{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fb4fb-095d-4fe1-a87e-1e56e7059246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce810aa-fb7c-40b6-bd8b-6811269564de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc10058-9081-44e4-a793-06c66b3e4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a6e38d9-b641-401c-b5d5-7e003c3eb237",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/rnn_short_memory.png\" width=500/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59d2d6-abd6-4cab-b5db-afe38017710b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f81b8dc5-88cb-424d-aa5d-4e6de78523e7",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/transformer_architecture.png\" width=350/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365415df-e226-4e74-8fb8-66244cbf7683",
   "metadata": {},
   "source": [
    "O encoder mapeia uma sequência de símbolos para uma sequência de representações contínuas. O decoder gera uma sequência de *output* de símbolos (1 a cada *timestep*). O modelo é autoregressivo, isto é, utiliza-se de informação do passado para prever o próximo símbolo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e207b-cb53-4ad4-882d-0b1de1d2c542",
   "metadata": {},
   "source": [
    "1. Input $\\rightarrow$ Input Embedding (lookup table).\n",
    "2. Input Embedding + Positional Encoding $\\rightarrow$ Positional Embedding.\n",
    "3. Encoder Layer\n",
    "    - <font color=\"red\">Multi Headed Attention (self)</font>\n",
    "    - FeedFoward Network\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f9b8a-f27d-4856-94b6-18a1f4c6a9a5",
   "metadata": {},
   "source": [
    "## **Encoder - Multi headed attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2b013-fff0-4a1e-a07c-fc8bfdfbb610",
   "metadata": {},
   "source": [
    "Permite associar uma palavra do input com outra palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba3bfc0-22c6-4d20-a366-2a647eb58396",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"figures/self_attention.png\" width=136/> </td>\n",
    "<td> <img src=\"figures/multi_head_attention.png\" width=175/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69907a1-9952-4e55-b9e3-5b9b98a3abbc",
   "metadata": {},
   "source": [
    ">The key/value/query concepts come from retrieval systems. For example, when you type a query to search for some video on Youtube, the search engine will map your query against a set of keys (video title, description, etc.) associated with candidate videos in the database, then present you the best matched videos (values).\n",
    "\n",
    "Ref: https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6be7b-f0e2-4039-8d85-f6b399cb7171",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/query_key_product.png\" width=275/> </center>\n",
    "\n",
    "<br>\n",
    "\n",
    "Suponha a frase ```Eu gosto de comer``` como input (positional embedding). Após a multiplicação matricial entre os vetores de *query* e os vetores de *keys* obtemos uma tabela de scores. Essa tabela nos diz quanto **foco** uma palavra deve colocar em outra palavra.\n",
    "\n",
    "\n",
    "|       | Eu  | gosto | de  | comer |\n",
    "|-------|-----|-------|-----|-------|\n",
    "| Eu    | s1  | s2    | s3  | s4    |\n",
    "| gosto | s5  | s6    | s7  | s8    |\n",
    "| de    | s9  | s10   | s11 | s12   |\n",
    "| comer | s13 | s14   | s15 | s16   |\n",
    "\n",
    "- A qual é posteriormente escalada pela raiz quadrada da dimensão das *querys* e *keys* ($\\sqrt{d_k}$). Ajuda a estabilizar os gradientes.\n",
    "\n",
    "- Aplica-se a função softmax (*row-wise*) para transformar os scores em probabilidades. Esses são os <font color = \"orange\">**Attention weights**</font>.\n",
    "\n",
    "- Depois multiplicamos os **attention weights** pela matriz de *values*.\n",
    "\n",
    "\n",
    "Resumindo:\n",
    "\n",
    "$$\n",
    "Attention(Q, K, V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0180422-55db-4e76-98a5-230921354385",
   "metadata": {},
   "source": [
    "Esse processo se chama **Multi** headed Attention porque, inicialmente, as matrizes **Q**, **K** e **V** são separadas em **N** grupos, cada um repreduzindo esse processo (**Self-Attention Head**).\n",
    "\n",
    "Por último os outputs de cada **Head** são concatenados e passam por um transformação linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97a868-8fb6-41d3-8b9f-dbfd2c5b767e",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/multi_head_attention.png\" width=175/> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cc302-95bf-4ff9-a29b-571194468f81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff401e24-029e-4263-be49-15a1db4961e2",
   "metadata": {},
   "source": [
    "## **Decoder - Masked Multi headed attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0230811-323c-4daa-a7d5-d2e177751562",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/transformer_architecture.png\" width=350/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107f519-07a8-46bb-b33a-b0beaa02437f",
   "metadata": {},
   "source": [
    "O decoder recebe informação do input:\n",
    "\n",
    "|       | Eu  | gosto | de  | comer |\n",
    "|-------|-----|-------|-----|-------|\n",
    "| Eu    | s1  | x     | x   | x     |\n",
    "| gosto | s5  | s6    | x   | x     |\n",
    "| de    | s9  | s10   | s11 | x     |\n",
    "| comer | s13 | s14   | s15 | s16   |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567b2f0-23f9-4385-9125-bd0d718b6d19",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/mask.png\" width=400/> </center>\n",
    "\n",
    "Depois de aplicar a função softmax temos:\n",
    "\n",
    "|       | Eu  | gosto | de  | comer |\n",
    "|-------|-----|-------|-----|-------|\n",
    "| Eu    | s1  | 0     | 0   | 0     |\n",
    "| gosto | s5  | s6    | 0   | 0     |\n",
    "| de    | s9  | s10   | s11 | 0     |\n",
    "| comer | s13 | s14   | s15 | s16   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a939de-4426-4edb-a163-0d0827965c14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355764a-1d13-487e-b0cc-022607add652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_playground",
   "language": "python",
   "name": "venv_playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
