{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7445f666-d3f2-4c7e-9d70-809eb29f4c14",
   "metadata": {},
   "source": [
    "# **Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0fd2c-0329-4ddf-a3d6-522b28ff4025",
   "metadata": {},
   "source": [
    "## **TOC:**\n",
    "\n",
    "- 1) **[Introduction](#intro)**\n",
    "\n",
    "- 2) **[Character Tokenization](#chartoken)**\n",
    "\n",
    "- 3) **[Word Tokenization](#wordtoken)**\n",
    "\n",
    "- 4) **[Subword Tokenization](#subwordtoken)**\n",
    "\n",
    "    - 4.1) **[Auto Tokenizer](#autotokenizer)**\n",
    "    - 4.2) **[Specific Tokenizer](#specifictokenizer)**\n",
    "\n",
    "- 5) **[Tokenizing the Dataset](#tokenizingdataset)**\n",
    "    \n",
    "    - 5.1) **[HuggingFace Dataset](#huggingdataset)**\n",
    "    \n",
    "    - 5.2) **[Custom Dataset](#customdataset)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86fb310-bf4e-4b0a-b93b-51215ac01146",
   "metadata": {},
   "source": [
    "Transformers provides a convenient AutoTokenizer class that allows you to quickly load\n",
    "the tokenizer associated with a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83c868-ac8f-42fc-bf22-983e94d251c8",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/attention_masks.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ea5e3f-709c-4be7-a689-76d59b974bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/rocabrera/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03d5f63d424e6ea7e045fb78bd4555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions = load_dataset(\"emotion\") ; emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08522788-c58d-40a5-be50-50a9c940bd69",
   "metadata": {},
   "source": [
    "## 2) **Character Tokenization** <a class=\"anchor\" id=\"chartoken\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2529a1-48ed-4e23-b860-89282dc0f7d4",
   "metadata": {},
   "source": [
    "Wrapper de um dicionario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "330c305e-ce1e-4130-8160-cd9007c2f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "\n",
    "# Supondo que cabe tudo na memoria\n",
    "vocab = set(\"\".join(train_ds[\"text\"]))\n",
    "char_mapping = {ch: idx for idx, ch in enumerate(sorted(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25d604e3-5387-4cc4-856c-4551f31997d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tokenizer(batch, mapping):\n",
    "    \n",
    "    if isinstance(batch[\"text\"], list):\n",
    "        mapped_tokens = [[mapping[char] for char in list(sentence)] for sentence in batch[\"text\"]]\n",
    "    else:\n",
    "        mapped_tokens = [mapping[char] for char in batch[\"text\"]]\n",
    "        \n",
    "    return {\"input_ids\": mapped_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2a94bcd-b0e3-4a12-bb62-d99482cc905d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79890e1c235c48e9bedc3e58cf254667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = train_ds.map(lambda x: char_tokenizer(x, char_mapping), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "771e0080-2cc0-4f5a-8b7a-70d4afbbdd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated',\n",
       " 'label': 0,\n",
       " 'input_ids': [9,\n",
       "  0,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  14,\n",
       "  20,\n",
       "  0,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  12,\n",
       "  0,\n",
       "  8,\n",
       "  21,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  20,\n",
       "  5,\n",
       "  4]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab8a3798-7239-4e83-a73d-462d8fefe09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 5, 19, 20, 0, 1], [20, 5, 19, 20, 0, 2]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [\"test a\", \"test b\"]\n",
    "[[char_mapping[char] for char in list(elem)] for elem in batch ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886c12d-09e3-45b5-9e8d-d053e90a455c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds.map(char_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cc957-50bb-47d6-9dda-dcd962b44c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[for char in list(train_ds[0][\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf40c05-9c3e-424a-83a3-d447dff34e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffeeb409-1a54-4d0c-9a53-dccf9659f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f863ba7-84f5-45d4-92e8-4c1042497ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31f29751ad645b6b70b34632e7a7cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "aux1 = train_ds.select(range(1000)).map(lambda x: tokenize(x, distilbert_tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2f3b7c-9686-4e67-aef6-c402613918c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7045711-0632-415b-8a27-15e336b32a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611d7d77b5654fef9e57dc90f12edfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "aux2 = train_ds.select(range(1000)).map(lambda x: tokenize(x, distilbert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29bc2cbc-05b8-4d85-b340-f16a0b35b2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  1045,\n",
       "  2064,\n",
       "  2175,\n",
       "  2013,\n",
       "  3110,\n",
       "  2061,\n",
       "  20625,\n",
       "  2000,\n",
       "  2061,\n",
       "  9636,\n",
       "  17772,\n",
       "  2074,\n",
       "  2013,\n",
       "  2108,\n",
       "  2105,\n",
       "  2619,\n",
       "  2040,\n",
       "  14977,\n",
       "  1998,\n",
       "  2003,\n",
       "  8300,\n",
       "  102],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a95782-94d7-4fa6-aff1-15514a7d9dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_huggingface",
   "language": "python",
   "name": "venv_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
